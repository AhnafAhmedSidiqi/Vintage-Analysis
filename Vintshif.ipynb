{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e47c437-65ab-4fd0-a9ce-5a2bd1f312b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-01 12:30:45.876 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.878 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.879 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.880 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.881 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.882 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.882 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.885 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.886 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.886 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.888 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.888 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.889 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.890 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.890 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.891 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.892 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.893 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.894 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.895 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.896 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.897 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-01 12:30:45.897 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m     st.stop()\n\u001b[32m     35\u001b[39m st.write(\u001b[33m\"\u001b[39m\u001b[33m### üìÅ Raw Data Preview\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m st.dataframe(\u001b[43mdf\u001b[49m.head(\u001b[32m10\u001b[39m))\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df.shape[\u001b[32m1\u001b[39m] < \u001b[32m3\u001b[39m:\n\u001b[32m     39\u001b[39m     st.error(\u001b[33m\"\u001b[39m\u001b[33mInput file must have at least 3 columns.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "# Title\n",
    "st.title(\"üìä Scorecard Vintage Analysis (M1, M2, ... buckets)\")\n",
    "\n",
    "# Sidebar: Upload & Settings\n",
    "st.sidebar.header(\"‚öôÔ∏è Settings\")\n",
    "uploaded_file = st.sidebar.file_uploader(\"Upload Excel or CSV file\", type=[\"xlsx\", \"csv\"])\n",
    "\n",
    "threshold = st.sidebar.number_input(\n",
    "    \"Threshold for 'Bad' (‚â• this value ‚Üí 1)\", \n",
    "    min_value=0, max_value=1000, \n",
    "    value=60, step=1\n",
    ")\n",
    "\n",
    "if uploaded_file is None:\n",
    "    st.info(\"üëà Please upload a file in the sidebar.\")\n",
    "    st.stop()\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    if uploaded_file.name.endswith('.xlsx'):\n",
    "        df = pd.read_excel(uploaded_file)\n",
    "    else:\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "except Exception as e:\n",
    "    st.error(f\"Error reading file: {e}\")\n",
    "    st.stop()\n",
    "\n",
    "st.write(\"### üìÅ Raw Data Preview\")\n",
    "st.dataframe(df.head(10))\n",
    "\n",
    "if df.shape[1] < 3:\n",
    "    st.error(\"Input file must have at least 3 columns.\")\n",
    "    st.stop()\n",
    "\n",
    "# Convert Bucket columns to dates\n",
    "df.columns = [\n",
    "    pd.to_datetime(col.split(' ', 1)[1], format='%b-%y').strftime('%Y-%m-%d')\n",
    "    if col.startswith('Bucket ') else col\n",
    "    for col in df.columns\n",
    "]\n",
    "\n",
    "# Sort OpenDate\n",
    "df = df.sort_values('OpenDate').reset_index(drop=True)\n",
    "df['OpenDate'] = df['OpenDate'].dt.to_period('M').dt.start_time\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# AUTO-SHIFT FUNCTION\n",
    "# ------------------------------\n",
    "def auto_shift_rows(df):\n",
    "    df_copy = df.copy()\n",
    "    df_copy['OpenDate'] = pd.to_datetime(df_copy['OpenDate'])\n",
    "\n",
    "    month_cols = [col for col in df_copy.columns if col[:4].isdigit()]\n",
    "    month_dt_cols = [pd.to_datetime(c) for c in month_cols]\n",
    "\n",
    "    def shift_row(row):\n",
    "        open_dt = row['OpenDate']\n",
    "        start_idx = next((i for i, d in enumerate(month_dt_cols) if d >= open_dt), len(month_cols)-1)\n",
    "        shifted_cols = month_cols[start_idx:] + month_cols[:start_idx]\n",
    "        return row[shifted_cols].values\n",
    "\n",
    "    df_copy[month_cols] = df_copy.apply(shift_row, axis=1, result_type='expand')\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "df_aligned = auto_shift_rows(df)\n",
    "\n",
    "# ------------------------------\n",
    "# RENAME: first 3 columns same, rest = M1, M2, ...\n",
    "# ------------------------------\n",
    "cols = df.columns.tolist()\n",
    "month_cols = cols[3:]\n",
    "new_col_names = cols[:3] + [f\"M{i+1}\" for i in range(len(month_cols))]\n",
    "df_aligned.columns = new_col_names\n",
    "st.write(\"### üî§ Renamed Columns (First 3 preserved)\")\n",
    "st.write(df_aligned.columns.tolist())\n",
    "\n",
    "# ------------------------------\n",
    "# BINARIZE\n",
    "# ------------------------------\n",
    "cols_to_update = df_aligned.columns[3:]\n",
    "df_binarized = df_aligned.copy()\n",
    "df_binarized[cols_to_update] = df_aligned[cols_to_update].where(\n",
    "    df_aligned[cols_to_update].isna(),\n",
    "    (df_aligned[cols_to_update] >= threshold).astype(int)\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# PROPAGATE 1s TO THE RIGHT\n",
    "# ------------------------------\n",
    "def propagate_ones(row):\n",
    "    row = row.copy()\n",
    "    activated = False\n",
    "    for i in range(len(row)):\n",
    "        if not pd.isna(row.iloc[i]):\n",
    "            if row.iloc[i] == 1:\n",
    "                activated = True\n",
    "            if activated:\n",
    "                row.iloc[i] = 1\n",
    "    return row\n",
    "\n",
    "df_propagated = df_binarized.copy()\n",
    "df_propagated[cols_to_update] = df_binarized[cols_to_update].apply(propagate_ones, axis=1)\n",
    "\n",
    "st.write(\"### üîÅ After Propagation (1s spread rightwards)\")\n",
    "st.dataframe(df_propagated.head(10))\n",
    "\n",
    "# ------------------------------\n",
    "# SUMMARY\n",
    "# ------------------------------\n",
    "sum_vals = df_propagated[cols_to_update].sum()\n",
    "count_vals = df_propagated[cols_to_update].count()\n",
    "\n",
    "summary_df = pd.DataFrame({'Sum': sum_vals, 'Count': count_vals})\n",
    "st.write(\"### üìä Column-wise Summary\")\n",
    "st.dataframe(summary_df)\n",
    "\n",
    "# ------------------------------\n",
    "# PLOT\n",
    "# ------------------------------\n",
    "summary_plot = summary_df\n",
    "#summary_plot = summary_df.sort_values(by='Count', ascending=False)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(25, 10))\n",
    "\n",
    "bars = ax1.bar(summary_plot.index, summary_plot['Count'], label='Observations (Count)')\n",
    "ax1.set_ylabel('Observations (Count)')\n",
    "ax1.set_xlabel('Vintage Bucket')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "line = ax2.plot(summary_plot.index, summary_plot['Sum'],color='red', marker='o', linestyle='-', linewidth=2, label='Bad (Sum)')\n",
    "ax2.set_ylabel('Bad (Sum)')\n",
    "\n",
    "plt.title(f'Vintage Buckets: Observations vs Bad (Threshold = {threshold})')\n",
    "fig.tight_layout()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "st.pyplot(fig)\n",
    "\n",
    "# ------------------------------\n",
    "# ZIP DOWNLOAD\n",
    "# ------------------------------\n",
    "csv_processed = df_propagated.to_csv(index=False).encode('utf-8')\n",
    "csv_summary = summary_df.to_csv().encode('utf-8')\n",
    "\n",
    "img_buf = io.BytesIO()\n",
    "fig.savefig(img_buf, format='png', dpi=300, bbox_inches='tight')\n",
    "img_buf.seek(0)\n",
    "\n",
    "zip_buffer = io.BytesIO()\n",
    "with zipfile.ZipFile(zip_buffer, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "    zf.writestr(\"processed_vintage_data.csv\", csv_processed)\n",
    "    zf.writestr(\"vintage_summary.csv\", csv_summary)\n",
    "    zf.writestr(\"vintage_analysis_plot.png\", img_buf.getvalue())\n",
    "\n",
    "zip_buffer.seek(0)\n",
    "\n",
    "st.download_button(\n",
    "    label=\"üì¶ Download All (ZIP)\",\n",
    "    data=zip_buffer,\n",
    "    file_name=\"vintage_analysis_output.zip\",\n",
    "    mime=\"application/zip\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8207fcd0-725a-4c79-8428-103e0780696a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
